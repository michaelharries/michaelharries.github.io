---
layout: post
title:  "LLMs in the Enterprise - Avoid the Event Horizon"
date:   2024-06-02 12:00:00 -0700
categories: [LLM, startup, enterprise computing, IGA, patterns]
categories: [LLM, startup, enterprise computing, IGA, patterns]
---

![Image of a black hole showing event horizon](/assets/event_horizon_image_dall-e.webp)

For many companies, the cost and time to implement new systems is  a heavy anchor, slowing ROI and impact. An important emerging pattern is for vendors to add Large Language Model (LLM) powered capabilities to simplify access to deeply buried functions, much like giving users a treasure map to navigate complex software. Done well, this can accelerate implementation, slash training times, and provide realtime policy configuration audit and update.
 
Enterprise computing isn't my main focus these days, as [Robotics Hub](https://theroboticshub.com]) has me far more captivated by emerging robotics and AI. However, I revisited my former beat earlier this week to share some insights at Identiverse. Many thanks to Sanjay Nadimpalli, CEO of Tuebora, for the invitation. (I funded Tuebora back in the early days at Citrix Startup Accelerator*.)
 
Here’s a rundown of the talk:
- LLMs (AI) are a profound shift in our computing toolkit with massive implications for how we think about and use knowledge.
- Much of the media coverage is overblown, partly due to our tendency toward anthropomorphism—assigning human qualities and agency to anything showing the slightest hint of intelligence. And how could we not, given the impressive capabilities of LLMs, including endowing robots with [implicit knowledge about the world](https://www.youtube.com/watch?v=CnkM0AecxYA).
- However, LLMs are still in their infancy and have clear breakage points, such as creating spurious data when pushed to the edge of their competence (known as hallucinations if we want to be anthropomorphic).
- For environments with high cost for mistakes, it makes sense to stay well away from the event horizon of _promised_ and emerging LLM capabilities. That is, **start where the technology is competent and stable**.
- Enterprises using LLMs should:
   - Prevent costly mistakes
   - Keep humans in the loop
   - Use strong safeguards against AI errors, or "hallucinations"
   - Manage data leakage risks
- One standout opportunity for vendors and customers is using LLMs to cut through costs by simplifying access to deeply buried functions, effectively handing users a treasure map to navigate complex software. This can speed up installations, reduce training time, and keep policies up-to-date effortlessly.
The implication is that we will see far more agile IT organizations, able to take on new initiatives and implement at a much faster pace, leading to significant IT-driven productivity improvements.
 
In the IGA space, this translates to faster setups, easier daily use, and quicker review cycles. If you’re in the market for an IGA solution, I recommend giving my friends at [Tuebora](https://tuebora.com) a call to explore the possibilities.

__

At the [Robotics Hub](https://theroboticshub.com), we take a pragmatic approach to finding and working with ground breaking companies that use emerging robotics and AI breakthroughs to solve large scale, real world challenges.

\* Citrix Startup Accelerator was an enterprise-computing startup accelerator that ran from 2010-2015 in Santa Clara, investing ~$250k per portfolio company.