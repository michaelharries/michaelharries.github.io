---
layout: post
title:  "We're all over-rotated on AI"
date:   2024-05-17 16:00:00 -0700
categories: AI
---


Why are we so credulous when it comes to AI?

Large Language Models/transformers are phenomenal, and excitement around these technologies is appropriate, but good grief, how much of the discussion seriously jumps the shark? 

Perhaps this is due to biases in how we think.

We like to anthropomorphize almost everything. 

Consider how easily we see faces in [inanimate objects](https://lnkd.in/gjEe_USG), how [Eliza](https://lnkd.in/gpBy_EPA) was heralded by some as an amazing psychotherapist, how early Roombas were given [names](https://lnkd.in/g3Nv5BMU), or how the ancients would see natural phenomena like the wind as having [emotions](https://lnkd.in/g8mxSdNu). We generalize from slices of behavior or shapes that we associate with people.

Given which, what chance do we have at taking a cold-eyed view of the realities of something that works with language as well as todays AI/large language models? 

With all of our biases tending toward overgeneralization, it's no wonder that so much of the discussion around these technologies trends to the breathless and even fantastical. 

We need clarity of language around the realities of today's AI. The pragmatics, if you like. What does it actually do? Where strong and where weak? Where does it bring economic and social wins, where is it fragile, where should it be regulated, where not? What are the grounded, near term risks to our informational world?

We also need clarity around the incentives driving various commentators, what drives different positions in marketing, who wins, who loses?
